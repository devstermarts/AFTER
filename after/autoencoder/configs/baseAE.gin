from __gin__ import dynamic_registration



import after
from after import autoencoder
from after.autoencoder.networks import SimpleNetsStream
from after.autoencoder.networks import encodec_discriminator
import torch
import cached_conv 




# Model 
SR = 44100
LATENT_SIZE = 64
PQMF_BANDS = 16 #Set to 1 if no pqmf


## NETWORK 
BASE_CHANNELS = 64
KERNEL_SIZE = 5
DECODER_RATIO = 1.5 # Sets the size of decoder compared to encoder
USE_NOISE_GENERATOR = False


## TRAINING
FREEZE_ENCODER_STEPS = 500000
WARMUP_STEPS = 500000
MAX_STEPS = 1000000
REGULARISATION_WEIGHT  = 0.1
REGULARISATION_WARMUP = 100000

cached_conv.get_padding:
    mode = "causal"

SimpleNetsStream.TanhBottleneck:
    sigma = 0.01
    scale = 3
    
SimpleNetsStream.AutoEncoder:
    in_channels = %PQMF_BANDS
    channels = %BASE_CHANNELS
    pqmf_bands =  %PQMF_BANDS
    z_channels = %LATENT_SIZE
    multipliers = [1, 2, 4, 4, 8, 8] # Multipliers of number of channels for each block
    factors = [2, 2, 2, 4, 4]  # Factors of upsampling for each block
    dilations = [1, 3, 9]
    kernel_size = %KERNEL_SIZE
    bottleneck  =  @SimpleNetsStream.TanhBottleneck() #@SimpleNetsStream.TanhBottleneck()
    use_norm = False   #Wheter to use group normalization : DISABLE FOR STREAMING MODELS
    decoder_ratio = %DECODER_RATIO
    use_loudness = True
    use_noise = %USE_NOISE_GENERATOR 



encodec_discriminator.EncodecDiscriminator:
    filters = 64
    n_ffts=[206, 334, 542, 876, 1418, 2296]
    hop_lengths=[103, 167, 271, 438, 709, 1148]
    win_lengths = [206, 334, 542, 876, 1418, 2296]
    normalize_losses = True
    spec_scale_pow = 0.5
    weights={
        "feature_matching": 20.0,
        "adversarial": 0.
        }

autoencoder.trainer.Trainer:
    discriminator = @encodec_discriminator.EncodecDiscriminator()

autoencoder.core.WaveformDistance:
    norm = "L1"

autoencoder.core.SpectralDistance:
    scales=[32, 64, 128, 256, 512, 1024, 2048]
    sr=%SR
    mel_bands=[5, 10, 20, 40, 80, 160, 320]
    

autoencoder.core.MultiResolutionSTFTLoss:
        fft_sizes= [2048, 1024, 512, 256, 128, 64, 32]
        hop_sizes = [512, 256, 128, 64, 32, 16, 8]
        win_lengths = [2048, 1024, 512, 256, 128, 64, 32]
        window = "hann_window"
        w_sc = 1.0
        w_log_mag = 1.0
        w_lin_mag = 0.
        w_phs = 0.0
        sample_rate = %SR
        scale = None
        n_bins = None
        perceptual_weighting = True
        scale_invariance = False


autoencoder.trainer.Trainer:
    sr=%SR
    max_steps=%MAX_STEPS
    warmup_steps=%WARMUP_STEPS
    freeze_encoder_step=%FREEZE_ENCODER_STEPS
    waveform_losses = [(1., @autoencoder.core.MultiResolutionSTFTLoss())]
    multiband_distances = []
    reg_losses = []
    update_discriminator_every = 4


autoencoder.trainer.Trainer.fit:
    steps_display=100
    rec_loss_decay=0.999996
    weight_regularisation_loss=%REGULARISATION_WEIGHT
    warmup_regularisation_loss=%REGULARISATION_WARMUP
